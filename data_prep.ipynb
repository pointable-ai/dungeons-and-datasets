{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "noteable": {
          "output_collection_id": "84b2b536-a57f-4eb1-8037-43bdddd0f5eb"
        },
        "ExecuteTime": {
          "end_time": "2023-09-05T23:53:34.015366+00:00",
          "start_time": "2023-09-05T23:52:47.544269+00:00"
        },
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "!unzip data.zip -d data/"
      ],
      "id": "0029f60e"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "noteable": {
          "output_collection_id": "ba01be57-e0b2-4c4f-a50b-88f6b94f1fa4"
        },
        "ExecuteTime": {
          "end_time": "2023-09-06T00:00:22.322432+00:00",
          "start_time": "2023-09-06T00:00:22.166717+00:00"
        }
      },
      "outputs": [],
      "source": [
        "# we're going to write a utility function to flatten out the entries\n",
        "# in any given data, this pattern is used often in 5e tools\n",
        "def flatten_entries(data):\n",
        "    # Base case: If data is a string, return it in a list\n",
        "    if isinstance(data, str):\n",
        "        return [data]\n",
        "\n",
        "    # For lists: iterate through each item and flatten\n",
        "    if isinstance(data, list):\n",
        "        result = []\n",
        "        for item in data:\n",
        "            result.extend(flatten_entries(item))\n",
        "        return result\n",
        "\n",
        "    # For dictionaries: look for the \"entries\" key and flatten its content\n",
        "    if isinstance(data, dict):\n",
        "        if \"entries\" in data:\n",
        "            return flatten_entries(data[\"entries\"])\n",
        "        return []\n",
        "    return []"
      ],
      "id": "0a6b39b1"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "noteable": {
          "output_collection_id": "aa848b13-f86d-48d6-b2bc-8dea292229bc"
        },
        "ExecuteTime": {
          "end_time": "2023-09-06T00:00:28.524935+00:00",
          "start_time": "2023-09-06T00:00:28.180750+00:00"
        }
      },
      "outputs": [],
      "source": "import os\nimport json\n\n# list all of the files in the bestiary data directory\n# filtering out the ones that are fluff or purely metadata\n# with no relevant monster information\nbase_bestiary_files = list(filter(lambda x: x.startswith('bestiary'), os.listdir('data/bestiary')))\n\n# fluff files (monster descriptions are separate from the core data files)\n# so we're going to join them all together into one big dictionary\n# keyed on the monster name + source (there are sometimes duplicate names)\nmonsters = {}\n\nfor base_file in base_bestiary_files: \n    with open('data/bestiary/' + base_file, 'r') as f:\n        # json parse the file and then get the monster data\n        # from the json\n        monster_data = json.loads(f.read())['monster']\n\n        # iterate through the monster data\n        for monster in monster_data:\n            key = monster['name'] + '|' + monster['source']\n            # if the monster name is already in the dictionary\n            # then we need to merge the data\n            if key in monster_data:\n                # merge the data\n                monsters[key] = {**monsters[key], **monster}\n            else:\n                # otherwise just add the data to the dictionary\n                monsters[key] = monster\n",
      "id": "8b5cb6c9"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "noteable": {
          "output_collection_id": "9c3443dd-85ea-4a62-a1dd-57115a71fdc8"
        },
        "ExecuteTime": {
          "end_time": "2023-09-06T00:00:30.476008+00:00",
          "start_time": "2023-09-06T00:00:30.157810+00:00"
        }
      },
      "outputs": [],
      "source": "# now we want to get the monster descriptions\n# and add them to the dictionary\nfor fluff_file in filter(lambda x: x.startswith('fluff-bestiary'), os.listdir('data/bestiary')):\n    with open('data/bestiary/' + fluff_file, 'r') as f:\n        fluff_data = json.loads(f.read())['monsterFluff']\n\n        # iterate through the fluff data\n        for fluff in fluff_data:\n            key = fluff['name'] + '|' + fluff['source']\n            # if the monster name is already in the dictionary\n            # then we need to merge the data\n            if 'entries' in fluff and key in monsters:\n                # merge the data\n                monsters[key]['descriptions'] = flatten_entries(fluff['entries'])\n",
      "id": "75732294"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "scrolled": false,
        "noteable": {
          "output_collection_id": "4cbbbbbb-7a9a-483e-bd49-b10bc074d761"
        },
        "ExecuteTime": {
          "end_time": "2023-09-05T23:59:41.796261+00:00",
          "start_time": "2023-09-05T23:59:41.638756+00:00"
        }
      },
      "outputs": [],
      "source": "# print the first 10 monsters\nfor key, value in list(monsters.items())[:10]:\n    # pretty print the monster data\n    print(json.dumps(value, indent=4))",
      "id": "eadfb658"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": false,
        "noteable": {
          "output_collection_id": "903f6442-1484-4b8f-9642-509de74615bf"
        },
        "ExecuteTime": {
          "end_time": "2023-09-06T00:00:40.047825+00:00",
          "start_time": "2023-09-06T00:00:39.866420+00:00"
        }
      },
      "outputs": [],
      "source": "from collections import defaultdict\n\nmonster_texts = []\n\ndef add_text_to_embed(key, field, monster_entry):\n    text = \"\"\n    for trait in monster_entry.get(field):\n        if type(trait) == str:\n            text += trait + \"\\n\"\n            continue\n        if trait.get(\"name\") is not None:\n            text += trait[\"name\"] + \"\\n\"\n        for entry in trait[\"entries\"]:\n            text += \"\\n\".join(flatten_entries(entry)) + \"\\n\"\n    [monster_name, monster_source] = key.split(\"|\")\n    monster_texts.append({\n        \"monster_name\": monster_name,\n        \"monster_source\": monster_source,\n        \"field\": field,\n        \"text\": text\n    })\n\nfor key, monster in monsters.items():\n    for field in [\"trait\", \"action\", \"legendary\", \"bonus\", \"descriptions\"]:\n        if field in monster and monster[field] is not None:\n            add_text_to_embed(key, field, monster)\n\nfor item in monster_texts[:10]:\n    print(item)",
      "id": "42a0408d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dump the monster text to be separately processed"
      ],
      "id": "f4703a07"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "noteable": {
          "output_collection_id": "620b8c29-9574-425d-be6e-4688168bb414"
        },
        "ExecuteTime": {
          "end_time": "2023-09-06T00:02:13.667431+00:00",
          "start_time": "2023-09-06T00:02:13.472504+00:00"
        },
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": "with open(\"./monster_text.json\", \"w\") as fp:\n    json.dump(monster_texts, fp)",
      "id": "45bb2e91"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "selected_hardware_size": "small",
    "kernel_info": {
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}